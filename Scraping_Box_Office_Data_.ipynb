{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM96mKMKLXkHRiTCjb1ZzXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Reben80/Data110-32213/blob/main/Scraping_Box_Office_Data_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scraping Box Office Data Using BeautifulSoup and Requests\n",
        "\n",
        "#### Introduction\n",
        "This Python script automates the process of extracting box office data from BoxOfficeMojo's weekend chart. Utilizing the `requests` library, it fetches the webpage content and employs `BeautifulSoup` for parsing the HTML to isolate the box office table. The script meticulously iterates through table rows, capturing essential details such as rank, release, gross earnings, and more, for each movie listed. The extracted data is then structured and saved into a CSV file named \"box_office_data.csv\". This approach facilitates easy aggregation, analysis, and storage of box office performance data for further analysis or reporting.\n"
      ],
      "metadata": {
        "id": "RICzleUClRx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "TiwsBIFYlzrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVkq8OpFz24r"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.boxofficemojo.com/weekend/chart/\"\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "# Use the correct class or id for the table\n",
        "table = soup.find('table', {'class': 'mojo-body-table'})\n",
        "\n",
        "data = []\n",
        "\n",
        "if table:\n",
        "    rows = table.find_all('tr')[1:]  # Assuming the first row is the header\n",
        "\n",
        "    for row in rows:\n",
        "        cells = row.find_all('td')\n",
        "        if len(cells) >= 9:  # Ensure there are enough cells\n",
        "            entry = {\n",
        "                'rank': cells[0].text.strip(),\n",
        "                'release': cells[1].text.strip(),\n",
        "                'gross': cells[2].text.strip(),\n",
        "                'lw': cells[3].text.strip(),\n",
        "                'theaters': cells[4].text.strip(),\n",
        "                'change': cells[5].text.strip(),\n",
        "                'average': cells[6].text.strip(),\n",
        "                'total_gross': cells[7].text.strip(),\n",
        "                'weeks': cells[8].text.strip(),\n",
        "                # 'distributor': cells[9].text.strip() if len(cells) > 9 else ''\n",
        "            }\n",
        "            data.append(entry)\n",
        "\n",
        "    if data:\n",
        "        csv_file = \"box_office_data.csv\"\n",
        "        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
        "            writer.writeheader()\n",
        "            for item in data:\n",
        "                writer.writerow(item)\n",
        "        print(f\"Data saved to {csv_file}\")\n",
        "    else:\n",
        "        print(\"No data extracted from the table.\")\n",
        "else:\n",
        "    print(\"Table not found in the page.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/box_office_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wVyQWgIv22uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "zGFKNFsm3U-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.head(5)\n",
        "plt.bar(data['gross'],data['weeks'])"
      ],
      "metadata": {
        "id": "OrHG0klW3b_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df.head(5)\n",
        "plt.barh(data['gross'],data['weeks'])"
      ],
      "metadata": {
        "id": "c5OmShp14uW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove $ and commas, then convert to float\n",
        "data['weeks'] = data['weeks'].str.replace('[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mOnYBwGV5LH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.barh(data['gross'],data['weeks'])"
      ],
      "metadata": {
        "id": "PHMiBFBw56qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correcting the sorting method\n",
        "sorted_data = data.sort_values(by='weeks', ascending=True)  # or ascending=False to reverse the order\n",
        "\n",
        "# Now plotting with matplotlib\n",
        "plt.barh(sorted_data['gross'], sorted_data['weeks'])\n",
        "\n"
      ],
      "metadata": {
        "id": "2tjdYfTrkB_Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}